{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#1. Loading required modules"
   ],
   "metadata": {
    "id": "63MGm65eCjRr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ug3u-V4-BWTi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, MissingIndicator\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "EfxflAM87I3M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('gender_classification_v7.csv')\n",
    "features = df.loc[:, df.columns != 'gender']\n",
    "label = df['gender']\n",
    "print(features)\n",
    "print(df.isna().sum())"
   ],
   "metadata": {
    "id": "0-ydbL4lDXIa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#3. Check for missing values:"
   ],
   "metadata": {
    "id": "T5BZb-AnDXnb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.isna().sum())"
   ],
   "metadata": {
    "id": "glKyIdt4DcKz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_missing_values(X_full):\n",
    "    import numpy as np\n",
    "    Col_names=X_full.columns\n",
    "    X_full=X_full.to_numpy()\n",
    "    rng = np.random.RandomState(4)\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    missing_samples[:n_missing_samples] = True\n",
    "\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[missing_samples, missing_features] = np.nan\n",
    "    X_missing=pd.DataFrame(X_missing)\n",
    "    X_missing.columns=Col_names\n",
    "    return X_missing\n",
    "\n"
   ],
   "metadata": {
    "id": "l8vxkVPpDip8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "features_df_with_missing_values=add_missing_values(features)\n",
    "print(features_df_with_missing_values.isna().sum())\n",
    "print(features_df_with_missing_values.head(60))"
   ],
   "metadata": {
    "id": "vZLGvx7YIUCc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Imputing the missing values using three different methods and assign the imputed output datasets into variables:"
   ],
   "metadata": {
    "id": "sNhwID7JGHQz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#First way, imputing by row mean\n",
    "df_features_row_mean= features_df_with_missing_values.copy().T\n",
    "imputer_mean = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "imputer_mean = imputer_mean.fit(df_features_row_mean)\n",
    "df_features_row_mean = imputer_mean.transform(df_features_row_mean).T\n",
    "df_features_row_mean = pd.DataFrame(df_features_row_mean, columns=features_df_with_missing_values.columns)\n",
    "print(df_features_row_mean.isna().sum())\n",
    "\n",
    "#Second way, imputing by column most frequent\n",
    "df_features_col_most_frequent=features_df_with_missing_values.copy()\n",
    "imputer_col_most_frequent = SimpleImputer(missing_values = np.nan, strategy = \"most_frequent\")\n",
    "imputer_col_most_frequent = imputer_col_most_frequent.fit(df_features_col_most_frequent)\n",
    "df_features_col_most_frequent = imputer_col_most_frequent.transform(df_features_col_most_frequent)\n",
    "df_features_col_most_frequent = pd.DataFrame(df_features_col_most_frequent, columns=features_df_with_missing_values.columns)\n",
    "print(df_features_col_most_frequent.isna().sum())\n",
    "\n",
    "\n",
    "#Third way, imputing using KNN\n",
    "df_features_KNN = features_df_with_missing_values.copy()\n",
    "imputer_KNN = KNNImputer(n_neighbors = 3)\n",
    "imputer_KNN = imputer_KNN.fit(df_features_KNN)\n",
    "df_features_KNN = imputer_KNN.transform(df_features_KNN)\n",
    "df_features_KNN = pd.DataFrame(df_features_KNN, columns=features_df_with_missing_values.columns)\n",
    "print(df_features_KNN.isna().sum())"
   ],
   "metadata": {
    "id": "nQDXRX4TIotK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#5. Preprocessing - performing Normalization for each one of the 3 methods\n"
   ],
   "metadata": {
    "id": "GdbJRpF8IsY8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Normalizing for first way(row mean)\n",
    "transformer_row_mean = preprocessing.Normalizer()\n",
    "df_row_mean_normalized = transformer_row_mean.transform(df_features_row_mean)\n",
    "df_row_mean_normalized = pd.DataFrame(df_row_mean_normalized, columns=features_df_with_missing_values.columns)\n",
    "print(df_row_mean_normalized.head(10))\n",
    "\n",
    "#Normalizing for second way(column most frequent)\n",
    "transformer_column_most_frequent = preprocessing.Normalizer()\n",
    "df_column_most_frequent_normalized = transformer_column_most_frequent.transform(df_features_col_most_frequent)\n",
    "df_column_most_frequent_normalized = pd.DataFrame(df_column_most_frequent_normalized, columns=features_df_with_missing_values.columns)\n",
    "print(df_column_most_frequent_normalized.head(10))\n",
    "\n",
    "#Normalizing for third way(KNN imputation)\n",
    "transformer_KNN = preprocessing.Normalizer()\n",
    "df_KNN_normalized = transformer_KNN.transform(df_features_KNN)\n",
    "df_KNN_normalized = pd.DataFrame(df_KNN_normalized, columns=features_df_with_missing_values.columns)\n",
    "print(df_KNN_normalized.head(10))\n",
    "\n",
    "\"\"\"Q5 - B\"\"\"\n",
    "\n",
    "sns.countplot(x= label)\n",
    "# i used chatgpt here to find the value counts command in seaborn\n",
    "print(label.value_counts())\n"
   ],
   "metadata": {
    "id": "wzahU-AlJV3c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing data balancing"
   ],
   "metadata": {
    "id": "46Pr9C1CLnlL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "copy_features = features.copy()\n",
    "copy_label = label.copy()\n",
    "nm_version = 2\n",
    "near_miss = NearMiss(version=nm_version)\n",
    "Features_Resampled_NM, Label_Resampled_NM = near_miss.fit_resample(copy_features, copy_label)\n",
    "print(Label_Resampled_NM.value_counts())\n",
    "\n",
    "smote = SMOTE()\n",
    "Features_Resampled_SMOTE, Label_Resampled_SMOTE = smote.fit_resample(features, label)\n",
    "print(Label_Resampled_SMOTE.value_counts())"
   ],
   "metadata": {
    "id": "WTtWHavyMF5S",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "outputId": "be1a9fb9-ade6-439e-fa0d-c88340447459"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Female    2500\n",
      "Male      2500\n",
      "Name: gender, dtype: int64\n",
      "Male      2501\n",
      "Female    2501\n",
      "Name: gender, dtype: int64\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\n#all of this is from chat gpt\\nSMOTE (Synthetic Minority Over-sampling Technique):\\nSMOTE addresses class imbalance by creating synthetic samples for the minority class. It selects an instance, finds its nearest neighbors from the same class, and generates new instances along the line connecting them. This expands the minority class, improving its representation. Advantages: Effective in increasing minority class samples, mitigating class imbalance. Disadvantages: Can introduce noise, leading to overfitting. Doesn't consider feature distribution, which might impact quality of synthetic samples.\""
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#7. Train test split:"
   ],
   "metadata": {
    "id": "pg_K-4_gNjbb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#first df\n",
    "X_train_row_mean, X_test_row_mean, y_train_row_mean, y_test_row_mean = train_test_split(df_row_mean_normalized, label, test_size = 0.2, random_state=5)\n",
    "\n",
    "#Second df\n",
    "X_train_col_most_frequent, X_test_col_most_frequent, y_train_col_most_frequent, y_test_col_most_frequent = train_test_split(df_column_most_frequent_normalized, label, test_size = 0.2, random_state=5)\n",
    "\n",
    "#Third df\n",
    "X_train_KNN, X_test_KNN, y_train_KNN, y_test_KNN = train_test_split(df_KNN_normalized, label, test_size = 0.2, random_state=5)\n"
   ],
   "metadata": {
    "id": "9Uobk5J_Nl5j"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#8. Training models (for both imputed datasets):\n",
    "\n"
   ],
   "metadata": {
    "id": "p32CMu4SNEQb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"Q8 - A\"\"\"\n",
    "# The three chosen models are: Logistic Regression, Catboost, Naive Bayes Classifier on train set\n",
    "\n",
    "'''Logistic Regression'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=42)\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "'''XGBoost'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=42)\n",
    "model2 = xgb.XGBClassifier()\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_labels_train = label_encoder.fit_transform(y_train)\n",
    "encoded_labels_test = label_encoder.transform(y_test)\n",
    "model2.fit(X_train, encoded_labels_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "accuracy = accuracy_score(encoded_labels_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "'''Naive Bayes'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=42)\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "\n",
    "'''Q8 - B'''\n",
    "# Used ChatGPT for hyperparameters\n",
    "# Logistic Regression:\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "# First df\n",
    "lr_classifier = LogisticRegression(random_state=42)\n",
    "lr_grid_search = GridSearchCV(lr_classifier, lr_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "lr_grid_search.fit(X_train_row_mean, y_train_row_mean)\n",
    "best_lr_model = lr_grid_search.best_estimator_\n",
    "y_pred_lr1 = best_lr_model.predict(X_test_row_mean)\n",
    "accuracy_lr1 = accuracy_score(y_test_row_mean, y_pred_lr1)\n",
    "print(\"Logistic Regression Accuracy for the first DF:\", accuracy_lr1)\n",
    "\n",
    "# Second df\n",
    "lr_grid_search.fit(X_train_col_most_frequent, y_train_col_most_frequent)\n",
    "best_lr_model = lr_grid_search.best_estimator_\n",
    "y_pred_lr2 = best_lr_model.predict(X_test_col_most_frequent)\n",
    "accuracy_lr2 = accuracy_score(y_test_col_most_frequent, y_pred_lr2)\n",
    "print(\"Logistic Regression Accuracy for the Second DF:\", accuracy_lr2)\n",
    "\n",
    "# Third df\n",
    "lr_grid_search.fit(X_train_KNN, y_train_KNN)\n",
    "best_lr_model = lr_grid_search.best_estimator_\n",
    "y_pred_lr3 = best_lr_model.predict(X_test_KNN)\n",
    "accuracy_lr3 = accuracy_score(y_test_KNN, y_pred_lr3)\n",
    "print(\"Logistic Regression Accuracy for the Third DF:\", accuracy_lr3)\n",
    "\n",
    "# Gaussian Naive Bayes:\n",
    "nb_param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "# First df\n",
    "nb_classifier = GaussianNB()\n",
    "nb_grid_search = GridSearchCV(nb_classifier, nb_param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "nb_grid_search.fit(X_train_row_mean, y_train_row_mean)\n",
    "best_nb_model = nb_grid_search.best_estimator_\n",
    "y_pred_nb1 = best_nb_model.predict(X_test_row_mean)\n",
    "accuracy_nb1 = accuracy_score(y_test_row_mean, y_pred_nb1)\n",
    "print(\"Naive Bayes Accuracy for first df:\", accuracy_nb1)\n",
    "\n",
    "# Second df\n",
    "nb_grid_search.fit(X_train_col_most_frequent, y_train_col_most_frequent)\n",
    "best_nb_model = nb_grid_search.best_estimator_\n",
    "y_pred_nb2 = best_nb_model.predict(X_test_col_most_frequent)\n",
    "accuracy_nb2 = accuracy_score(y_test_col_most_frequent, y_pred_nb2)\n",
    "print(\"Naive Bayes Accuracy for the second df:\", accuracy_nb2)\n",
    "\n",
    "# Third df\n",
    "nb_grid_search.fit(X_train_KNN, y_train_KNN)\n",
    "best_nb_model = nb_grid_search.best_estimator_\n",
    "y_pred_nb3 = best_nb_model.predict(X_test_KNN)\n",
    "accuracy_nb3 = accuracy_score(y_test_KNN, y_pred_nb3)\n",
    "print(\"Naive Bayes Accuracy for the Third df:\", accuracy_nb3)\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "grid_search = GridSearchCV(model2, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, encoded_labels_train)\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(encoded_labels_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "''' Q8 - C'''\n",
    "best_lr_hyperparameters = lr_grid_search.best_params_\n",
    "print(\"Best Hyperparameters for Logistic Regression:\", best_lr_hyperparameters)\n",
    "\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(encoded_labels_test, y_pred)\n",
    "print(\"Best Hyperparameters for XGBoost:\", grid_search.best_params_)\n",
    "\n",
    "best_nb_model = nb_grid_search.best_estimator_\n",
    "best_nb_hyperparameters = best_nb_model.get_params()\n",
    "print(\"Best Hyperparameters for Multinomial Naive Bayes:\", best_nb_hyperparameters)"
   ],
   "metadata": {
    "id": "WLveUiA9Y7Iz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "55aa7435-d348-4ba9-84ba-9b4353e507d3"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9600399600399601\n",
      "Accuracy: 0.961038961038961\n",
      "Number of mislabeled points out of a total 1001 points : 36\n",
      "Logistic Regression Accuracy for the first DF: 0.8151848151848152\n",
      "Logistic Regression Accuracy for the Second DF: 0.9300699300699301\n",
      "Logistic Regression Accuracy for the Third DF: 0.949050949050949\n",
      "Naive Bayes Accuracy for first df: 0.8551448551448552\n",
      "Naive Bayes Accuracy for the second df: 0.936063936063936\n",
      "Naive Bayes Accuracy for the Third df: 0.948051948051948\n",
      "Accuracy: 0.968031968031968\n",
      "Best Hyperparameters for Logistic Regression: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best Hyperparameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best Hyperparameters for Multinomial Naive Bayes: {'priors': None, 'var_smoothing': 1e-09}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting to train and test and performing training and prediction for each model"
   ],
   "metadata": {
    "id": "WXR9AHo9Y3gJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "imputed_datasets = [('df_row_mean', df_row_mean_normalized), ('df_col_most_frequent', df_column_most_frequent_normalized), ('df_KNN', df_KNN_normalized)]\n",
    "\n",
    "for dataset_name, dataset in imputed_datasets:\n",
    "  X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size=0.2, random_state=42)\n",
    "\n",
    "  log_model = LogisticRegression()\n",
    "\n",
    "  LR = log_model.fit(X_train, y_train)\n",
    "\n",
    "  LR_train_preds = LR.predict(X_train)\n",
    "  print(f\"train prediction logistic regression {dataset_name}\\n\" + classification_report(LR_train_preds, y_train))\n",
    "\n",
    "  LR_test_preds = LR.predict(X_test)\n",
    "  print(f\"test prediction logistic regression {dataset_name}\\n\" + classification_report(LR_test_preds, y_test))\n",
    "\n",
    "\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "  label_encoded = label_encoder.fit_transform(label)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(dataset, label_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "  XGBmodel = XGBClassifier()\n",
    "\n",
    "  XGB = XGBmodel.fit(X_train, y_train)\n",
    "\n",
    "  XGB_train_preds = XGB.predict(X_train)\n",
    "  print(f\"train prediction XGB {dataset_name} \\n\" + classification_report(XGB_train_preds, y_train))\n",
    "\n",
    "  XGB_test_preds = XGB.predict(X_test)\n",
    "  print(f\"test prediction XGB {dataset_name}\\n\" + classification_report(XGB_test_preds, y_test))\n",
    "\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(dataset, label_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "  GNBmodel = GaussianNB()\n",
    "\n",
    "  GNB = GNBmodel.fit(X_train, y_train)\n",
    "\n",
    "  GNB_train_preds = GNB.predict(X_train)\n",
    "  print(f\"train prediction GNB {dataset_name} \\n\" + classification_report(GNB_train_preds, y_train))\n",
    "\n",
    "  GNB_test_preds = GNB.predict(X_test)\n",
    "  print(f\"test prediction GNB {dataset_name} \\n\" + classification_report(GNB_test_preds, y_test))\n"
   ],
   "metadata": {
    "id": "OGXWpYFLZyHh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ec6f6748-7684-4e4c-be79-0e5f554b7dca"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train prediction logistic regression df_row_mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.81      0.82      0.82      1974\n",
      "        Male       0.83      0.81      0.82      2026\n",
      "\n",
      "    accuracy                           0.82      4000\n",
      "   macro avg       0.82      0.82      0.82      4000\n",
      "weighted avg       0.82      0.82      0.82      4000\n",
      "\n",
      "test prediction logistic regression df_row_mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.80      0.80      0.80       501\n",
      "        Male       0.80      0.80      0.80       500\n",
      "\n",
      "    accuracy                           0.80      1001\n",
      "   macro avg       0.80      0.80      0.80      1001\n",
      "weighted avg       0.80      0.80      0.80      1001\n",
      "\n",
      "train prediction XGB df_row_mean \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2000\n",
      "           1       1.00      1.00      1.00      2000\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "test prediction XGB df_row_mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       503\n",
      "           1       0.95      0.95      0.95       498\n",
      "\n",
      "    accuracy                           0.95      1001\n",
      "   macro avg       0.95      0.95      0.95      1001\n",
      "weighted avg       0.95      0.95      0.95      1001\n",
      "\n",
      "train prediction GNB df_row_mean \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      1901\n",
      "           1       0.88      0.84      0.86      2099\n",
      "\n",
      "    accuracy                           0.85      4000\n",
      "   macro avg       0.85      0.85      0.85      4000\n",
      "weighted avg       0.85      0.85      0.85      4000\n",
      "\n",
      "test prediction GNB df_row_mean \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       489\n",
      "           1       0.85      0.82      0.83       512\n",
      "\n",
      "    accuracy                           0.83      1001\n",
      "   macro avg       0.83      0.83      0.83      1001\n",
      "weighted avg       0.83      0.83      0.83      1001\n",
      "\n",
      "train prediction logistic regression df_col_most_frequent\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.91      0.95      0.93      1925\n",
      "        Male       0.95      0.92      0.93      2075\n",
      "\n",
      "    accuracy                           0.93      4000\n",
      "   macro avg       0.93      0.93      0.93      4000\n",
      "weighted avg       0.93      0.93      0.93      4000\n",
      "\n",
      "test prediction logistic regression df_col_most_frequent\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.91      0.95      0.93       480\n",
      "        Male       0.96      0.92      0.94       521\n",
      "\n",
      "    accuracy                           0.93      1001\n",
      "   macro avg       0.93      0.93      0.93      1001\n",
      "weighted avg       0.94      0.93      0.93      1001\n",
      "\n",
      "train prediction XGB df_col_most_frequent \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1998\n",
      "           1       0.99      0.99      0.99      2002\n",
      "\n",
      "    accuracy                           0.99      4000\n",
      "   macro avg       0.99      0.99      0.99      4000\n",
      "weighted avg       0.99      0.99      0.99      4000\n",
      "\n",
      "test prediction XGB df_col_most_frequent\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       500\n",
      "           1       0.95      0.95      0.95       501\n",
      "\n",
      "    accuracy                           0.95      1001\n",
      "   macro avg       0.95      0.95      0.95      1001\n",
      "weighted avg       0.95      0.95      0.95      1001\n",
      "\n",
      "train prediction GNB df_col_most_frequent \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      1891\n",
      "           1       0.96      0.91      0.94      2109\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.94      0.94      0.94      4000\n",
      "weighted avg       0.94      0.94      0.94      4000\n",
      "\n",
      "test prediction GNB df_col_most_frequent \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       473\n",
      "           1       0.96      0.91      0.94       528\n",
      "\n",
      "    accuracy                           0.94      1001\n",
      "   macro avg       0.94      0.94      0.94      1001\n",
      "weighted avg       0.94      0.94      0.94      1001\n",
      "\n",
      "train prediction logistic regression df_KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.95      0.96      0.96      1984\n",
      "        Male       0.96      0.95      0.96      2016\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.96      0.96      0.96      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n",
      "test prediction logistic regression df_KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.94      0.95      0.95       495\n",
      "        Male       0.95      0.94      0.95       506\n",
      "\n",
      "    accuracy                           0.95      1001\n",
      "   macro avg       0.95      0.95      0.95      1001\n",
      "weighted avg       0.95      0.95      0.95      1001\n",
      "\n",
      "train prediction XGB df_KNN \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2001\n",
      "           1       1.00      1.00      1.00      1999\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "test prediction XGB df_KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       499\n",
      "           1       0.96      0.95      0.95       502\n",
      "\n",
      "    accuracy                           0.95      1001\n",
      "   macro avg       0.95      0.95      0.95      1001\n",
      "weighted avg       0.95      0.95      0.95      1001\n",
      "\n",
      "train prediction GNB df_KNN \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      2009\n",
      "           1       0.95      0.96      0.96      1991\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.96      0.96      0.96      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n",
      "test prediction GNB df_KNN \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       504\n",
      "           1       0.95      0.95      0.95       497\n",
      "\n",
      "    accuracy                           0.95      1001\n",
      "   macro avg       0.95      0.95      0.95      1001\n",
      "weighted avg       0.95      0.95      0.95      1001\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#b. Verbally explain which model resulted with the best outcome with consideration to over-fitting, under-fitting and proper-fitting."
   ],
   "metadata": {
    "id": "0q70fd0FZzqS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Printing classification_report of the test set using the best model "
   ],
   "metadata": {
    "id": "QjsR7CqOaRnC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "imputed_datasets = [('df_row_mean', df_row_mean_normalized), ('df_col_most_frequent', df_column_most_frequent_normalized), ('df_KNN', df_KNN_normalized)]\n",
    "\n",
    "for dataset_name, dataset in imputed_datasets:\n",
    "  X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size=0.2, random_state=42)\n",
    "\n",
    "  log_model = LogisticRegression()\n",
    "\n",
    "  LR = log_model.fit(X_train, y_train)\n",
    "\n",
    "  LR_test_preds = LR.predict(X_test)\n",
    "  print(f\"test prediction logistic regression {dataset_name}\\n\" + classification_report(LR_test_preds, y_test))"
   ],
   "metadata": {
    "id": "lqPM-0PVa1Ab",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5ac6b160-02a5-47a4-bfa5-9244574a92e7"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test prediction logistic regression df_row_mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.80      0.80      0.80       501\n",
      "        Male       0.80      0.80      0.80       500\n",
      "\n",
      "    accuracy                           0.80      1001\n",
      "   macro avg       0.80      0.80      0.80      1001\n",
      "weighted avg       0.80      0.80      0.80      1001\n",
      "\n",
      "test prediction logistic regression df_col_most_frequent\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.91      0.95      0.93       480\n",
      "        Male       0.96      0.92      0.94       521\n",
      "\n",
      "    accuracy                           0.93      1001\n",
      "   macro avg       0.93      0.93      0.93      1001\n",
      "weighted avg       0.94      0.93      0.93      1001\n",
      "\n",
      "test prediction logistic regression df_KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.94      0.95      0.95       495\n",
      "        Male       0.95      0.94      0.95       506\n",
      "\n",
      "    accuracy                           0.95      1001\n",
      "   macro avg       0.95      0.95      0.95      1001\n",
      "weighted avg       0.95      0.95      0.95      1001\n"
     ]
    }
   ]
  }
 ]
}
